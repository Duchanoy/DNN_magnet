{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import mpld3\n",
    "mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json(name):\n",
    "    print(name)\n",
    "    with open(name) as data_file:    \n",
    "            data = json.load(data_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_proces(name,Deface=100,NumSam=200):\n",
    "    datos=read_json(name)\n",
    "    entradas=read_json('_'.join(('inp',name)))\n",
    "    train=np.array([[0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0]])\n",
    "    referencia=[0]\n",
    "    for key in datos.keys():\n",
    "        print(len(datos[key]))\n",
    "        for k,exp in enumerate(datos[key]):\n",
    "            VelC=exp[\"velocity\"]\n",
    "            forceC=exp[\"force\"]\n",
    "            VelCj=[round(elem, 1) for elem in VelC]\n",
    "            Conj=set(VelCj)\n",
    "            infbar=100\n",
    "            for elem in list(Conj):\n",
    "                indices=[i for i,x in enumerate(VelCj) if x==elem]\n",
    "                for ind in range(len(indices)-1):\n",
    "                    if forceC[indices[ind]] == forceC[indices[ind+1]] and indices[ind]> 120:\n",
    "                        reference = [indices[ind],indices[ind+1]]\n",
    "                        break\n",
    "                    elif abs(forceC[indices[ind]]-forceC[indices[ind+1]])<infbar and indices[ind+1]-indices[ind]>20 and indices[ind+1]-indices[ind]<200 and indices[ind]> 120:\n",
    "                        tempref = [indices[ind],indices[ind+1]]\n",
    "                        infbar = abs(forceC[indices[ind]]-forceC[indices[ind+1]])\n",
    "                if 'reference' in locals():\n",
    "                    break\n",
    "            \n",
    "            if 'reference' in locals():    \n",
    "                Deface = reference[0]\n",
    "                NumSam = reference[1] - reference[0]\n",
    "                del reference\n",
    "            else:\n",
    "                Deface = tempref[0]\n",
    "                NumSam = tempref[1] - tempref[0]\n",
    "                del tempref\n",
    "            referencia.append(referencia[-1]+NumSam+1)\n",
    "            for element in range(NumSam+1):\n",
    "                caso=list()\n",
    "                caso.append(entradas[key][\"Ap\"])\n",
    "                caso.append(entradas[key][\"Ag\"])\n",
    "                caso.append(entradas[key][\"h\"])\n",
    "                caso.append(entradas[key][\"L\"])\n",
    "                caso.append(entradas[key][\"viscocidad\"])\n",
    "                caso.append(entradas[key][\"Ty\"][k]/1000)\n",
    "                caso.append((exp[\"velocity\"][element+Deface])*0.001)\n",
    "                caso.append(exp[\"displace\"][element+Deface])\n",
    "                caso.append(exp[\"force\"][element+Deface])\n",
    "                casonp=np.array(caso)\n",
    "                #print(len(casonp))\n",
    "                train=np.append(train,[casonp],axis=0)\n",
    "            \n",
    "    return train[2:][:],referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Target_C(data):\n",
    "    Arn=(data[0]+((data[1])/2))\n",
    "    Fn=((12*(data[4])*Arn*(data[6]/10))/((data[1])*data[2]*data[2]))\n",
    "    Fn=Fn*(data[0]*data[3])\n",
    "    Fty=data[8]-Fn\n",
    "    c=((Fty*data[2])/(data[3]*data[0]*data[5]*1000))\n",
    "    return Fty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def force_limit(data):\n",
    "    Arn=(data[0]+((data[1])/2))\n",
    "    Fn=((12*(data[4])*Arn*(data[6]))/((data[1])*data[2]*data[2]))\n",
    "    Fn=Fn*(data[0]*data[3])\n",
    "    #c=2.07+((12*data[4]*data[0]*data[6])/((12*data[4]*data[0]*data[6])+(0.4*data[1]*data[2]*data[5])))\n",
    "    c=1.07\n",
    "    Fty= (c*data[3]*data[0]*data[5]*1000)/(data[2])\n",
    "    fr=Fn+Fty\n",
    "    #print(fr)\n",
    "    #print(data[8])\n",
    "    return fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twofluidexp.json\n",
      "inp_twofluidexp.json\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "[0, 121, 242, 368, 498, 623, 745, 869, 993, 1115, 1239, 1361, 1485, 1605, 1731, 1854, 1973, 2098, 2223, 2348, 2465, 2589, 2712, 2833, 2959, 3082, 3207, 3328, 3447, 3570, 3694, 3816, 3938, 4060, 4185, 4311, 4436, 4562, 4687, 4812, 4935, 5053, 5179, 5303, 5424, 5550, 5673, 5796, 5920, 6045, 6170, 6293, 6415, 6538, 6661, 6784, 6905, 7028, 7152, 7275, 7398, 7524, 7651, 7774, 7896, 8015, 8135, 8260, 8386, 8510, 8632, 8755, 8879, 9004, 9124, 9241, 9366, 9491, 9615, 9738, 9864, 9988, 10113, 10239, 10364, 10485, 10610, 10735, 10855, 10973, 11097, 11223, 11349, 11474, 11598, 11721, 11841, 11965, 12090, 12215, 12340, 12463, 12588, 12717, 12843, 12957, 13083, 13208, 13333]\n"
     ]
    }
   ],
   "source": [
    "train,refer=data_proces(\"twofluidexp.json\",Deface=120,NumSam=260)\n",
    "#print(train.shape)\n",
    "#print(train[1:4])\n",
    "np.random.shuffle(train)\n",
    "#train[1:4,8:9].shape\n",
    "#print(train[20][])\n",
    "print(refer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Agregar funcion para limpiar la gráfica \n",
    "# Evita duplicar elementos \n",
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Deep_neural_network(\n",
    "    learning_rate = 1e-2,\n",
    "    batch_size=20,\n",
    "    Drop_prob=1.0,\n",
    "    n_nodes_hl1 = 30,\n",
    "    n_nodes_hl2 = 30,\n",
    "    n_nodes_hl3 = 30,\n",
    "    n_nodes_hl4 = 30,\n",
    "    beta=.01,\n",
    "    n_classes=1):\n",
    "    \n",
    "    # limpiar gráficas anteriores \n",
    "    reset_graph()\n",
    "    \n",
    "    #input place holder \n",
    "    x= tf.placeholder(tf.float32,[batch_size,8], name='input_placeholder')\n",
    "    #output place holder\n",
    "    y =tf.placeholder(tf.float32,[batch_size,1],name='output_placeholder')\n",
    "    \n",
    "    hidden_1_layer = {'weights':tf.Variable(tf.random_normal([8, n_nodes_hl1])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))}\n",
    "\n",
    "    hidden_2_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))}\n",
    "\n",
    "    hidden_3_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl2, n_nodes_hl3])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl3]))}\n",
    "    \n",
    "    hidden_4_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_nodes_hl4])),\n",
    "                      'biases':tf.Variable(tf.random_normal([n_nodes_hl4]))}\n",
    "    \n",
    "\n",
    "\n",
    "    output_layer = {'weights':tf.Variable(tf.random_normal([n_nodes_hl3, n_classes])),\n",
    "                    'biases':tf.Variable(tf.random_normal([n_classes])),}\n",
    "    \n",
    "    l1 = tf.add(tf.matmul(x,hidden_1_layer['weights']), hidden_1_layer['biases'])\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    l1 = tf.nn.dropout(l1,Drop_prob)\n",
    "\n",
    "    l2 = tf.add(tf.matmul(l1,hidden_2_layer['weights']), hidden_2_layer['biases'])\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    l2 = tf.nn.dropout(l2,Drop_prob)\n",
    "\n",
    "    l3 = tf.add(tf.matmul(l2,hidden_3_layer['weights']), hidden_3_layer['biases'])\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    l3 = tf.nn.dropout(l3,Drop_prob)\n",
    "    \n",
    "    l4 = tf.add(tf.matmul(l3,hidden_4_layer['weights']), hidden_4_layer['biases'])\n",
    "    l4 = tf.nn.relu(l4)\n",
    "    l4 = tf.nn.dropout(l4,Drop_prob)\n",
    "    \n",
    "    #l5 = tf.add(tf.matmul(l4,hidden_5_layer['weights']), hidden_5_layer['biases'])\n",
    "    #l5 = tf.nn.relu(l5)\n",
    "    #l5 = tf.nn.dropout(l5,Drop_prob)\n",
    "\n",
    "    output = tf.matmul(l2,output_layer['weights']) + output_layer['biases']\n",
    "    \n",
    "    regularizer = tf.nn.l2_loss(hidden_1_layer['weights']) + tf.nn.l2_loss(hidden_2_layer['weights'])+tf.nn.l2_loss(hidden_3_layer['weights']) + tf.nn.l2_loss(hidden_4_layer['weights'])\n",
    "    \n",
    "    total_loss = tf.losses.mean_squared_error(output, y)\n",
    "   \n",
    "    tf.summary.scalar(\"Lost\",total_loss)\n",
    "    \n",
    "    loss = tf.reduce_mean(total_loss + beta * regularizer)\n",
    "    \n",
    "    tf.summary.scalar(\"Regularized_loss\",loss)\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "    \n",
    "    #generar logs\n",
    "    summaries = tf.summary.merge_all()\n",
    "    \n",
    "    \n",
    "    return dict(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        output=output,\n",
    "        total_loss = total_loss,\n",
    "        train_step = train_step,\n",
    "        summaries=summaries,\n",
    "        saver = tf.train.Saver() \n",
    "    )\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': <tf.Tensor 'add:0' shape=(20, 1) dtype=float32>,\n",
       " 'saver': <tensorflow.python.training.saver.Saver at 0x7fb09d63ef28>,\n",
       " 'summaries': <tf.Tensor 'Merge/MergeSummary:0' shape=() dtype=string>,\n",
       " 'total_loss': <tf.Tensor 'mean_squared_error/value:0' shape=() dtype=float32>,\n",
       " 'train_step': <tf.Operation 'Adam' type=NoOp>,\n",
       " 'x': <tf.Tensor 'input_placeholder:0' shape=(20, 8) dtype=float32>,\n",
       " 'y': <tf.Tensor 'output_placeholder:0' shape=(20, 1) dtype=float32>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deep_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def conv2d(x, W):\n",
    "#    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "#def maxpool2d(x):\n",
    "    #                        size of window         movement of window\n",
    "#    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convolutional_neural_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_network(g,data, num_epochs, num_steps = 15, batch_size = 20, verbose = True, save=False\n",
    "                  ,batch_pick=22,checkpoint=False,step=0):\n",
    "    tf.set_random_seed(2345)\n",
    "    print('Start training')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        writer = tf.summary.FileWriter(\"./LOGTEST\")\n",
    "        tf.summary.FileWriter.add_graph(writer,sess.graph)\n",
    "        \n",
    "        if checkpoint:\n",
    "            g['saver'].restore(sess, checkpoint)\n",
    "        training_losses = []\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0\n",
    "            dim,var=data.shape\n",
    "            for j in range(int(dim/batch_size)):\n",
    "\n",
    "                epoch_x=data[batch_size*(j):batch_size*(j+1),0:8]\n",
    "                \n",
    "                epoch_Y=data[batch_size*(j):batch_size*(j+1),8:9]\n",
    "                \n",
    "                    \n",
    "                feed_dict={g['x']: epoch_x, \n",
    "                           g['y']: epoch_Y\n",
    "                          }\n",
    "                \n",
    "                output,training_loss_, training_state,summ = sess.run([g['output'],g['total_loss'],\n",
    "                                                      g['train_step'],g[\"summaries\"]],\n",
    "                                                             feed_dict)\n",
    "                epoch_loss += training_loss_\n",
    "                \n",
    "            if (epoch%2 == 0):\n",
    "                writer.add_summary(summ,step+epoch)\n",
    "                \n",
    "                    \n",
    "            if verbose:\n",
    "                print(\"Average training loss for Epoch\", epoch, \":\", epoch_loss)\n",
    "                #print(output)\n",
    "            training_losses.append(epoch_loss)\n",
    "\n",
    "        if isinstance(save, str):\n",
    "            g['saver'].save(sess, save)\n",
    "\n",
    "    return training_losses,step+epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Paso=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13333, 9)\n",
      "Start training\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(100, 8), b.shape=(8, 30), m=100, n=30, k=8\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input_placeholder_0_0/_1, Variable/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/home/sia/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sia/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-cdb3d3fece82>\", line 3, in <module>\n    g = Deep_neural_network(learning_rate = 1e-2,batch_size=100,Drop_prob=1)\n  File \"<ipython-input-9-8d791ff84ccc>\", line 37, in Deep_neural_network\n    l1 = tf.add(tf.matmul(x,hidden_1_layer['weights']), hidden_1_layer['biases'])\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1844, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1289, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(100, 8), b.shape=(8, 30), m=100, n=30, k=8\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input_placeholder_0_0/_1, Variable/read)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(100, 8), b.shape=(8, 30), m=100, n=30, k=8\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input_placeholder_0_0/_1, Variable/read)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cdb3d3fece82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPaso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./One_2*30_2fluid.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPaso\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#losses,Paso = train_network(g, train, 1000,batch_size=100,verbose =False,save=\"./Exp_1*50_2fluid.ckpt\",checkpoint=\"./Exp_1*50_2fluid.ckpt\",step=Paso)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#losses = train_network(g, train, 1000,batch_size=1,verbose =False,save=\"./Twocase1.ckpt\",checkpoint=\"./OneCase.ckpt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-04678f4acd4a>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(g, data, num_epochs, num_steps, batch_size, verbose, save, batch_pick, checkpoint, step)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 output,training_loss_, training_state,summ = sess.run([g['output'],g['total_loss'],\n\u001b[1;32m     28\u001b[0m                                                       g['train_step'],g[\"summaries\"]],\n\u001b[0;32m---> 29\u001b[0;31m                                                              feed_dict)\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtraining_loss_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(100, 8), b.shape=(8, 30), m=100, n=30, k=8\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input_placeholder_0_0/_1, Variable/read)]]\n\nCaused by op 'MatMul', defined at:\n  File \"/home/sia/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/sia/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-cdb3d3fece82>\", line 3, in <module>\n    g = Deep_neural_network(learning_rate = 1e-2,batch_size=100,Drop_prob=1)\n  File \"<ipython-input-9-8d791ff84ccc>\", line 37, in Deep_neural_network\n    l1 = tf.add(tf.matmul(x,hidden_1_layer['weights']), hidden_1_layer['biases'])\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1844, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1289, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/sia/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMM launch failed : a.shape=(100, 8), b.shape=(8, 30), m=100, n=30, k=8\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](_arg_input_placeholder_0_0/_1, Variable/read)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "g = Deep_neural_network(learning_rate = 1e-2,batch_size=100,Drop_prob=1)\n",
    "t = time.time()\n",
    "print(train.shape)\n",
    "losses,Paso = train_network(g, train, 500,batch_size=100,verbose =False ,save=\"./One_2*30_2fluid.ckpt\",step=Paso)\n",
    "#losses,Paso = train_network(g, train, 1000,batch_size=100,verbose =False,save=\"./Exp_1*50_2fluid.ckpt\",checkpoint=\"./Exp_1*50_2fluid.ckpt\",step=Paso)\n",
    "#losses = train_network(g, train, 1000,batch_size=1,verbose =False,save=\"./Twocase1.ckpt\",checkpoint=\"./OneCase.ckpt\")\n",
    "print(\"It took\", time.time() - t, \"seconds to train.\")\n",
    "print(\"The average loss on the final epoch was:\", losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
